{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7262\n",
      "Epoch [2/100], Loss: 0.6852\n",
      "Epoch [3/100], Loss: 0.6719\n",
      "Epoch [4/100], Loss: 0.6918\n",
      "Epoch [5/100], Loss: 0.7213\n",
      "Epoch [6/100], Loss: 0.6963\n",
      "Epoch [7/100], Loss: 0.6727\n",
      "Epoch [8/100], Loss: 0.6679\n",
      "Epoch [9/100], Loss: 0.6988\n",
      "Epoch [10/100], Loss: 0.7034\n",
      "Epoch [11/100], Loss: 0.6881\n",
      "Epoch [12/100], Loss: 0.6809\n",
      "Epoch [13/100], Loss: 0.6918\n",
      "Epoch [14/100], Loss: 0.6664\n",
      "Epoch [15/100], Loss: 0.6766\n",
      "Epoch [16/100], Loss: 0.6827\n",
      "Epoch [17/100], Loss: 0.6843\n",
      "Epoch [18/100], Loss: 0.6717\n",
      "Epoch [19/100], Loss: 0.6956\n",
      "Epoch [20/100], Loss: 0.6571\n",
      "Epoch [21/100], Loss: 0.6701\n",
      "Epoch [22/100], Loss: 0.6729\n",
      "Epoch [23/100], Loss: 0.6647\n",
      "Epoch [24/100], Loss: 0.6443\n",
      "Epoch [25/100], Loss: 0.6408\n",
      "Epoch [26/100], Loss: 0.6750\n",
      "Epoch [27/100], Loss: 0.6041\n",
      "Epoch [28/100], Loss: 0.6266\n",
      "Epoch [29/100], Loss: 0.6414\n",
      "Epoch [30/100], Loss: 0.6522\n",
      "Epoch [31/100], Loss: 0.6760\n",
      "Epoch [32/100], Loss: 0.6775\n",
      "Epoch [33/100], Loss: 0.6118\n",
      "Epoch [34/100], Loss: 0.6705\n",
      "Epoch [35/100], Loss: 0.5964\n",
      "Epoch [36/100], Loss: 0.5994\n",
      "Epoch [37/100], Loss: 0.5726\n",
      "Epoch [38/100], Loss: 0.6022\n",
      "Epoch [39/100], Loss: 0.6072\n",
      "Epoch [40/100], Loss: 0.5718\n",
      "Epoch [41/100], Loss: 0.5649\n",
      "Epoch [42/100], Loss: 0.5537\n",
      "Epoch [43/100], Loss: 0.6796\n",
      "Epoch [44/100], Loss: 0.6054\n",
      "Epoch [45/100], Loss: 0.6240\n",
      "Epoch [46/100], Loss: 0.6201\n",
      "Epoch [47/100], Loss: 0.6225\n",
      "Epoch [48/100], Loss: 0.6017\n",
      "Epoch [49/100], Loss: 0.5674\n",
      "Epoch [50/100], Loss: 0.6330\n",
      "Epoch [51/100], Loss: 0.6153\n",
      "Epoch [52/100], Loss: 0.5541\n",
      "Epoch [53/100], Loss: 0.6110\n",
      "Epoch [54/100], Loss: 0.5467\n",
      "Epoch [55/100], Loss: 0.5253\n",
      "Epoch [56/100], Loss: 0.5850\n",
      "Epoch [57/100], Loss: 0.6012\n",
      "Epoch [58/100], Loss: 0.5553\n",
      "Epoch [59/100], Loss: 0.5779\n",
      "Epoch [60/100], Loss: 0.5278\n",
      "Epoch [61/100], Loss: 0.5430\n",
      "Epoch [62/100], Loss: 0.4945\n",
      "Epoch [63/100], Loss: 0.5300\n",
      "Epoch [64/100], Loss: 0.5908\n",
      "Epoch [65/100], Loss: 0.5816\n",
      "Epoch [66/100], Loss: 0.4379\n",
      "Epoch [67/100], Loss: 0.4475\n",
      "Epoch [68/100], Loss: 0.4833\n",
      "Epoch [69/100], Loss: 0.5359\n",
      "Epoch [70/100], Loss: 0.4915\n",
      "Epoch [71/100], Loss: 0.4734\n",
      "Epoch [72/100], Loss: 0.5171\n",
      "Epoch [73/100], Loss: 0.5750\n",
      "Epoch [74/100], Loss: 0.5222\n",
      "Epoch [75/100], Loss: 0.4675\n",
      "Epoch [76/100], Loss: 0.5198\n",
      "Epoch [77/100], Loss: 0.4658\n",
      "Epoch [78/100], Loss: 0.5268\n",
      "Epoch [79/100], Loss: 0.4682\n",
      "Epoch [80/100], Loss: 0.4581\n",
      "Epoch [81/100], Loss: 0.5028\n",
      "Epoch [82/100], Loss: 0.4897\n",
      "Epoch [83/100], Loss: 0.4408\n",
      "Epoch [84/100], Loss: 0.4422\n",
      "Epoch [85/100], Loss: 0.5101\n",
      "Epoch [86/100], Loss: 0.4579\n",
      "Epoch [87/100], Loss: 0.4880\n",
      "Epoch [88/100], Loss: 0.4861\n",
      "Epoch [89/100], Loss: 0.4492\n",
      "Epoch [90/100], Loss: 0.3974\n",
      "Epoch [91/100], Loss: 0.4250\n",
      "Epoch [92/100], Loss: 0.3723\n",
      "Epoch [93/100], Loss: 0.4242\n",
      "Epoch [94/100], Loss: 0.4462\n",
      "Epoch [95/100], Loss: 0.3887\n",
      "Epoch [96/100], Loss: 0.4685\n",
      "Epoch [97/100], Loss: 0.4133\n",
      "Epoch [98/100], Loss: 0.4288\n",
      "Epoch [99/100], Loss: 0.4254\n",
      "Epoch [100/100], Loss: 0.5031\n",
      "Test Accuracy: 70.50%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Simulate dataset (code from slides)\n",
    "features = torch.rand((1000, 50))\n",
    "labels = (features.sum(dim=1) > 25).float()\n",
    "\n",
    "# Splitting the data into training and testing sets -> here (80% for training, 20% for testing)\n",
    "split_idx = int(0.8 * len(features))\n",
    "train_features, test_features = features[:split_idx], features[split_idx:]\n",
    "train_labels, test_labels = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "# Creating the DataLoader for training and testing sets with defined batch size\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(train_features, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = TensorDataset(test_features, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model - define loss function and optimizer\n",
    "input_size = 50\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model on 100 epochs\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model on the test set (the 20% from above)\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs >= 0.5).float()\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets.unsqueeze(1)).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "\n",
    "# Computing the accuracy\n",
    "print(f'Test Accuracy: {100 * accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b2ed07406f43fefe29d7e6a5344fe55f2939fdcf75c25060c3ecc711fe31b42"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
